<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Assignment 3</title>
  <meta name="viewport" content="width=device-width">
  <meta name="description" content="Course materials and notes for Stanford class CS231n: Convolutional Neural Networks for Visual Recognition.">
  <link rel="canonical" href="index.html">

  <!-- Custom CSS -->
  <link rel="stylesheet" href="../../css/main.css">

  <!-- Google fonts -->
  <link href='https://fonts.googleapis.com/css?family=Roboto:400,300' rel='stylesheet' type='text/css'>

  <!-- Google tracking -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-46895817-2', 'auto');
    ga('send', 'pageview');
  </script>
</head>


    <body>

      <div id="header">
        <a href="">
          <img src="images/logo_2x.png" title="SenseTime" style="height:70px; position: absolute; left: 20px; top: 20px; ">
        </a>
        <!-- <a href="http://cuhk.edu.hk/english/index.html">
          <img src="images/cu_logo.jpg" style="height:50px; float: right; margin-right: 100px; margin-bottom: 18px;">
        </a> -->
      
        <a href="index.html">
          <h1> 高等计算机视觉 Advanced Computer Vision </h1>
        </a>
      
        <div style="clear:both;"></div>
      </div>

</header>


    <div class="page-content">
      <div class="wrap">
      <div class="post">

  <header class="post-header">
    <h1>Assignment 3</h1>
  </header>

  <article class="post-content">
  <p>This assignment is due on <strong>Wednesday, May 27 2020</strong> at 11:59pm PDT.</p>

<details>
<summary>Handy Download Links</summary>

 <ul>
  <li><a href="../../assignments/2020/assignment3_colab.zip">Option A: Colab starter code</a></li>
  <li><a href="../../assignments/2020/assignment3_jupyter.zip">Option B: Jupyter starter code</a></li>
</ul>
</details>

<ul>
  <li><a href="#goals">Goals</a></li>
  <li><a href="#setup">Setup</a>
    <ul>
      <li><a href="#option-a-google-colaboratory-recommended">Option A: Google Colaboratory (Recommended)</a></li>
      <li><a href="#option-b-local-development">Option B: Local Development</a></li>
    </ul>
  </li>
  <li><a href="#q1-image-captioning-with-vanilla-rnns-29-points">Q1: Image Captioning with Vanilla RNNs (29 points)</a></li>
  <li><a href="#q2-image-captioning-with-lstms-23-points">Q2: Image Captioning with LSTMs (23 points)</a></li>
  <li><a href="#q3-network-visualization-saliency-maps-class-visualization-and-fooling-images-15-points">Q3: Network Visualization: Saliency maps, Class Visualization, and Fooling Images (15 points)</a></li>
  <li><a href="#q4-style-transfer-15-points">Q4: Style Transfer (15 points)</a></li>
  <li><a href="#q5-generative-adversarial-networks-15-points">Q5: Generative Adversarial Networks (15 points)</a></li>
  <li><a href="#submitting-your-work">Submitting your work</a></li>
</ul>

<h3 id="goals">Goals</h3>

<p>In this assignment, you will implement recurrent neural networks and apply them to image captioning on the Microsoft COCO data. You will also explore methods for visualizing the features of a pretrained model on ImageNet, and use this model to implement Style Transfer. Finally, you will train a Generative Adversarial Network to generate images that look like a training dataset!</p>

<p>The goals of this assignment are as follows:</p>

<ul>
  <li>Understand the architecture of recurrent neural networks (RNNs) and how they operate on sequences by sharing weights over time.</li>
  <li>Understand and implement both Vanilla RNNs and Long-Short Term Memory (LSTM) networks.</li>
  <li>Understand how to combine convolutional neural nets and recurrent nets to implement an image captioning system.</li>
  <li>Explore various applications of image gradients, including saliency maps, fooling images, class visualizations.</li>
  <li>Understand and implement techniques for image style transfer.</li>
  <li>Understand how to train and implement a Generative Adversarial Network (GAN) to produce images that resemble samples from a dataset.</li>
</ul>

<h3 id="setup">Setup</h3>

<p>You should be able to use your setup from assignments 1 and 2.</p>

<p>You can work on the assignment in one of two ways: <strong>remotely</strong> on Google Colaboratory or <strong>locally</strong> on your own machine.</p>

<p><strong>Regardless of the method chosen, ensure you have followed the <a href="../../setup-instructions/index.html">setup instructions</a> before proceeding.</strong></p>

<h4 id="option-a-google-colaboratory-recommended">Option A: Google Colaboratory (Recommended)</h4>

<p><strong>Download.</strong> Starter code containing Colab notebooks can be downloaded <a href="../../assignments/2020/assignment3_colab.zip">here</a>.</p>

<p>If you choose to work with Google Colab, please familiarize yourself with the <a href="../../setup-instructions/index.html#working-remotely-on-google-colaboratory">recommended workflow</a>.</p>

<iframe style="display: block; margin: auto;" width="560" height="315" src="https://www.youtube.com/embed/IZUz4pRYlus" frameborder="0" allowfullscreen=""></iframe>

<p><strong>Note</strong>. Ensure you are periodically saving your notebook (<code class="language-plaintext highlighter-rouge">File -&gt; Save</code>) so that you don’t lose your progress if you step away from the assignment and the Colab VM disconnects.</p>

<p>Once you have completed all Colab notebooks <strong>except <code class="language-plaintext highlighter-rouge">collect_submission.ipynb</code></strong>, proceed to the <a href="#submitting-your-work">submission instructions</a>.</p>

<h4 id="option-b-local-development">Option B: Local Development</h4>

<p><strong>Download.</strong> Starter code containing jupyter notebooks can be downloaded <a href="../../assignments/2020/assignment3_jupyter.zip">here</a>.</p>

<p><strong>Install Packages</strong>. Once you have the starter code, activate your environment (the one you installed in the <a href="../../setup-instructions/index.html">Software Setup</a> page) and run <code class="language-plaintext highlighter-rouge">pip install -r requirements.txt</code>.</p>

<p><strong>Download data</strong>. Next, you will need to download the COCO captioning data, a pretrained SqueezeNet model (for TensorFlow), and a few ImageNet validation images. Run the following from the <code class="language-plaintext highlighter-rouge">assignment3</code> directory:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd </span>cs231n/datasets
./get_datasets.sh
</code></pre></div></div>
<p><strong>Start Jupyter Server</strong>. After you’ve downloaded the data, you can start the Jupyter server from the <code class="language-plaintext highlighter-rouge">assignment3</code> directory by executing <code class="language-plaintext highlighter-rouge">jupyter notebook</code> in your terminal.</p>

<p>Complete each notebook, then once you are done, go to the <a href="#submitting-your-work">submission instructions</a>.</p>

<p><strong>You can do Questions 3, 4, and 5 in TensorFlow or PyTorch. There are two versions of each of these notebooks, one for TensorFlow and one for PyTorch. No extra credit will be awarded if you do a question in both TensorFlow and PyTorch</strong></p>

<h3 id="q1-image-captioning-with-vanilla-rnns-29-points">Q1: Image Captioning with Vanilla RNNs (29 points)</h3>

<p>The notebook <code class="language-plaintext highlighter-rouge">RNN_Captioning.ipynb</code> will walk you through the implementation of an image captioning system on MS-COCO using vanilla recurrent networks.</p>

<h3 id="q2-image-captioning-with-lstms-23-points">Q2: Image Captioning with LSTMs (23 points)</h3>

<p>The notebook <code class="language-plaintext highlighter-rouge">LSTM_Captioning.ipynb</code> will walk you through the implementation of Long-Short Term Memory (LSTM) RNNs, and apply them to image captioning on MS-COCO.</p>

<h3 id="q3-network-visualization-saliency-maps-class-visualization-and-fooling-images-15-points">Q3: Network Visualization: Saliency maps, Class Visualization, and Fooling Images (15 points)</h3>

<p>The notebooks <code class="language-plaintext highlighter-rouge">NetworkVisualization-TensorFlow.ipynb</code>, and <code class="language-plaintext highlighter-rouge">NetworkVisualization-PyTorch.ipynb</code> will introduce the pretrained SqueezeNet model, compute gradients with respect to images, and use them to produce saliency maps and fooling images. Please complete only one of the notebooks (TensorFlow or PyTorch). No extra credit will be awardeded if you complete both notebooks.</p>

<h3 id="q4-style-transfer-15-points">Q4: Style Transfer (15 points)</h3>

<p>In thenotebooks <code class="language-plaintext highlighter-rouge">StyleTransfer-TensorFlow.ipynb</code> or <code class="language-plaintext highlighter-rouge">StyleTransfer-PyTorch.ipynb</code> you will learn how to create images with the content of one image but the style of another. Please complete only one of the notebooks (TensorFlow or PyTorch). No extra credit will be awardeded if you complete both notebooks.</p>

<h3 id="q5-generative-adversarial-networks-15-points">Q5: Generative Adversarial Networks (15 points)</h3>

<p>In the notebooks <code class="language-plaintext highlighter-rouge">GANS-TensorFlow.ipynb</code> or <code class="language-plaintext highlighter-rouge">GANS-PyTorch.ipynb</code> you will learn how to generate images that match a training dataset, and use these models to improve classifier performance when training on a large amount of unlabeled data and a small amount of labeled data. Please complete only one of the notebooks (TensorFlow or PyTorch). No extra credit will be awarded if you complete both notebooks.</p>

<h3 id="submitting-your-work">Submitting your work</h3>

<p><strong>Important</strong>. Please make sure that the submitted notebooks have been run and the cell outputs are visible.</p>

<p>Once you have completed all notebooks and filled out the necessary code, there are <strong><em>two</em></strong> steps you must follow to submit your assignment:</p>

<p><strong>1.</strong> If you selected Option A and worked on the assignment in Colab, open <code class="language-plaintext highlighter-rouge">collect_submission.ipynb</code> in Colab and execute the notebook cells. If you selected Option B and worked on the assignment locally, run the bash script in <code class="language-plaintext highlighter-rouge">assignment3</code> by executing <code class="language-plaintext highlighter-rouge">bash collectSubmission.sh</code>.</p>

<p>This notebook/script will:</p>

<ul>
  <li>Generate a zip file of your code (<code class="language-plaintext highlighter-rouge">.py</code> and <code class="language-plaintext highlighter-rouge">.ipynb</code>) called <code class="language-plaintext highlighter-rouge">a3.zip</code>.</li>
  <li>Convert all notebooks into a single PDF file.</li>
</ul>

<p><strong>Note for Option B users</strong>. You must have (a) <code class="language-plaintext highlighter-rouge">nbconvert</code> installed with Pandoc and Tex support and (b) <code class="language-plaintext highlighter-rouge">PyPDF2</code> installed to successfully convert your notebooks to a PDF file. Please follow these <a href="https://nbconvert.readthedocs.io/en/latest/install.html#installing-nbconvert">installation instructions</a> to install (a) and run <code class="language-plaintext highlighter-rouge">pip install PyPDF2</code> to install (b). If you are, for some inexplicable reason, unable to successfully install the above dependencies, you can manually convert each jupyter notebook to HTML (<code class="language-plaintext highlighter-rouge">File -&gt; Download as -&gt; HTML (.html)</code>), save the HTML page as a PDF, then concatenate all the PDFs into a single PDF submission using your favorite PDF viewer.</p>

<p>If your submission for this step was successful, you should see the following display message:</p>

<p><code class="language-plaintext highlighter-rouge">### Done! Please submit a3.zip and the pdfs to Gradescope. ###</code></p>

<p><strong>2.</strong> Submit the PDF and the zip file to <a href="https://www.gradescope.com/courses/103764">Gradescope</a>.</p>

<p><strong>Note for Option A users</strong>. Remember to download <code class="language-plaintext highlighter-rouge">a3.zip</code> and <code class="language-plaintext highlighter-rouge">assignment.pdf</code> locally before submitting to Gradescope.</p>

  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">

    <div class="footer-col-1 column">
      <ul>

        <li>
          <a href="https://github.com/cs231n">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            <span class="username">cs231n</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/cs231n">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
              </svg>
            </span>
            <span class="username">cs231n</span>
          </a>
        </li>
        <!-- <li>
          <a href="mailto:karpathy@cs.stanford.edu">karpathy@cs.stanford.edu</a>
        </li> -->
      </ul>
    </div>

    <div class="footer-col-2 column">

    </div>

    <div class="footer-col-3 column">

    </div>

  </div>

</footer>


    <!-- mathjax -->
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">
      // Make responsive
      MathJax.Hub.Config({
       "HTML-CSS": { linebreaks: { automatic: true } },
       "SVG": { linebreaks: { automatic: true } },
      });
    </script>

    </body>
</html>
